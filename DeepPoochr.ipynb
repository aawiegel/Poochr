{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-10-27 14:14:11--  https://s3.amazonaws.com/mordecai-geo/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.161.157\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.161.157|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1.5G) [application/octet-stream]\n",
      "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>]   1.53G  1.52MB/s    in 13m 25s \n",
      "\n",
      "2017-10-27 14:27:37 (1.95 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get pretrained vectors for word2vec\n",
    "\n",
    "!wget https://s3.amazonaws.com/mordecai-geo/GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnews_w2v = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431607246399),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593235015869),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnews_w2v.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apartment_complex', 0.7893964052200317),\n",
       " ('townhouse', 0.7727404236793518),\n",
       " ('apartments', 0.7152601480484009),\n",
       " ('bedroom', 0.7045778632164001),\n",
       " ('Apartments', 0.6661036014556885),\n",
       " ('house', 0.6628996133804321),\n",
       " ('duplex', 0.6575543880462646),\n",
       " ('rooming_house', 0.6564425230026245),\n",
       " ('townhome', 0.6522176265716553),\n",
       " ('fourplex', 0.648613691329956)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnews_w2v.most_similar(positive=['apartment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49586788]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(gnews_w2v['big'].reshape(1, -1), gnews_w2v['small'].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_w2v = gensim.models.KeyedVectors.load_word2vec_format('./data/glove_w2v_small.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70083666]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wiki_w2v['small'].reshape(1, -1), wiki_w2v['big'].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11008   , -0.38780999, -0.57615   , -0.27713999,  0.70520997,\n",
       "        0.53994   , -1.07860005, -0.40145999,  1.15040004, -0.56779999,\n",
       "        0.0038977 ,  0.52877998,  0.64560997,  0.47262001,  0.48548999,\n",
       "       -0.18407001,  0.18009999,  0.91396999, -1.19790006, -0.57779998,\n",
       "       -0.37985   ,  0.33605999,  0.77200001,  0.75555003,  0.45506001,\n",
       "       -1.76709998, -1.0503    ,  0.42566001,  0.41892999, -0.68326998,\n",
       "        1.56729996,  0.27684999, -0.61707997,  0.64638001, -0.076996  ,\n",
       "        0.37118   ,  0.13079999, -0.45137   ,  0.25398001, -0.74392003,\n",
       "       -0.086199  ,  0.24067999, -0.64819002,  0.83548999,  1.25020003,\n",
       "       -0.51379001,  0.04224   , -0.88117999,  0.71579999,  0.38519001], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_w2v['dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dog vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text_from_num(dogtime_html, synonyms, antonyms):\n",
    "    \"\"\"\n",
    "    Given a BeautifulSoup object dogtime_html generated from the dogtime website,\n",
    "    generate text from numeric features using synonym and antonym dictionaries\n",
    "    \"\"\"\n",
    "    dog_text = ''\n",
    "    \n",
    "    char_dict = dict()\n",
    "    for characteristic in dogtime_html.find_all(class_=\"characteristic item-trigger-title\"):\n",
    "        char_dict[characteristic.text.strip()] =\\\n",
    "                int(characteristic.find_next().find_next()['class'][1].split('-')[-1])\n",
    "    \n",
    "    for trait, value in char_dict.items():\n",
    "        if value > 3:\n",
    "            factor = value - 3\n",
    "\n",
    "            dog_text += factor*(synonyms[trait])\n",
    "            \n",
    "        elif value < 3:\n",
    "            factor = 3 - value\n",
    "            \n",
    "            dog_text += factor*(antonyms[trait])\n",
    "    \n",
    "    return dog_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://54.67.82.182/dogbreeds\")\n",
    "db = client.dogbreeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trait_synonyms = dict()\n",
    "trait_synonyms['Adaptability'] = 'adaptable '\n",
    "trait_synonyms['Adapts Well to Apartment Living'] = 'apartment '\n",
    "trait_synonyms['Affectionate with Family'] = 'cuddly '\n",
    "trait_synonyms['All Around Friendliness'] = 'friendly '\n",
    "trait_synonyms['Amount Of Shedding'] = ''\n",
    "trait_synonyms['Dog Friendly'] = 'dogs '\n",
    "trait_synonyms['Drooling Potential'] = ''\n",
    "trait_synonyms['Easy To Groom'] = 'grooming '\n",
    "trait_synonyms['Easy To Train'] = 'obedient '\n",
    "trait_synonyms['Energy Level'] = 'energetic '\n",
    "trait_synonyms['Exercise Needs'] = 'active '\n",
    "trait_synonyms['Friendly Toward Strangers'] = 'friendly '\n",
    "trait_synonyms['General Health'] = 'healthy '\n",
    "trait_synonyms['Good For Novice Owners'] = 'novice '\n",
    "trait_synonyms['Health Grooming'] = 'healthy '\n",
    "trait_synonyms['Incredibly Kid Friendly Dogs'] = 'children '\n",
    "trait_synonyms['Intelligence'] = 'intelligent '\n",
    "trait_synonyms['Intensity'] = ''\n",
    "trait_synonyms['Potential For Mouthiness'] = 'fetch '\n",
    "trait_synonyms['Potential For Playfulness'] = 'playful '\n",
    "trait_synonyms['Potential For Weight Gain'] = ''\n",
    "trait_synonyms['Prey Drive'] = 'hunting '\n",
    "trait_synonyms['Sensitivity Level'] = ''\n",
    "trait_synonyms['Size'] = 'big '\n",
    "trait_synonyms['Tendency To Bark Or Howl'] = ''\n",
    "trait_synonyms['Tolerates Being Alone'] = 'alone '\n",
    "trait_synonyms['Tolerates Cold Weather'] = 'cold '\n",
    "trait_synonyms['Tolerates Hot Weather'] = 'hot '\n",
    "trait_synonyms['Trainability'] = 'obedient '\n",
    "trait_synonyms['Wanderlust Potential'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trait_antonyms = dict()\n",
    "trait_antonyms['Adaptability'] = ''\n",
    "trait_antonyms['Adapts Well to Apartment Living'] = 'yard '\n",
    "trait_antonyms['Affectionate with Family'] = ''\n",
    "trait_antonyms['All Around Friendliness'] = ''\n",
    "trait_antonyms['Amount Of Shedding'] = 'clean '\n",
    "trait_antonyms['Dog Friendly'] = 'protective '\n",
    "trait_antonyms['Drooling Potential'] = 'clean '\n",
    "trait_antonyms['Easy To Groom'] = ''\n",
    "trait_antonyms['Easy To Train'] = ''\n",
    "trait_antonyms['Energy Level'] = 'calm '\n",
    "trait_antonyms['Exercise Needs'] = 'lazy '\n",
    "trait_antonyms['Friendly Toward Strangers'] = 'security '\n",
    "trait_antonyms['General Health'] = ''\n",
    "trait_antonyms['Good For Novice Owners'] = ''\n",
    "trait_antonyms['Health Grooming'] = ''\n",
    "trait_antonyms['Incredibly Kid Friendly Dogs'] = ''\n",
    "trait_antonyms['Intelligence'] = ''\n",
    "trait_antonyms['Intensity'] = 'relaxed '\n",
    "trait_antonyms['Potential For Mouthiness'] = 'safe '\n",
    "trait_antonyms['Potential For Playfulness'] = 'aloof '\n",
    "trait_antonyms['Potential For Weight Gain'] = 'thin '\n",
    "trait_antonyms['Prey Drive'] = ''\n",
    "trait_antonyms['Sensitivity Level'] = 'adaptable '\n",
    "trait_antonyms['Size'] = 'small '\n",
    "trait_antonyms['Tendency To Bark Or Howl'] = 'quiet '\n",
    "trait_antonyms['Tolerates Being Alone'] = ''\n",
    "trait_antonyms['Tolerates Cold Weather'] = ''\n",
    "trait_antonyms['Tolerates Hot Weather'] = ''\n",
    "trait_antonyms['Trainability'] = ''\n",
    "trait_antonyms['Wanderlust Potential'] = 'homebody '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.curdir, \"data\")\n",
    "image_dir = os.path.join(data_dir, 'Images', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog_dirs = [direct for direct in os.listdir(image_dir)\\\n",
    "            if os.path.isdir(os.path.join(image_dir, direct))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog_dirs.remove('not_dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog_breeds = [dog.split('-', 1)[1].lower() for dog in dog_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breed_text = dict()\n",
    "for breed, dog_dir in zip(dog_breeds, dog_dirs):\n",
    "    dog_content = db.dogbreeds.find_one({\"breed\" : breed})\n",
    "    dogtime_html = BeautifulSoup(dog_content[\"dogtime_content\"], \"lxml\")\n",
    "    breed_text[dog_dir] = generate_text_from_num(dogtime_html, trait_synonyms, trait_antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breed_vecs = dict()\n",
    "for breed, text in breed_text.items():\n",
    "    trait_list = text.split(' ')[:-2]\n",
    "    breed_vecs[breed] = np.zeros_like(wiki_w2v['dog'])\n",
    "    for trait in trait_list:\n",
    "        breed_vecs[breed] += wiki_w2v[trait]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58356476]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(breed_vecs['n02094433-Yorkshire_terrier'].reshape(1, -1), wiki_w2v['apartment'].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breed_mat = np.zeros((115, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breed_vecs['not_dog'] = np.zeros_like(breed_vecs['n02085620-Chihuahua'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breeds = np.load('breed_indices.npy').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for breed, index in breeds.items():\n",
    "    breed_mat[index] += breed_vecs[breed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.69011927,  -0.36988768,  -3.14270592, ...,  -9.92434216,\n",
       "         10.33327675,   6.50213337],\n",
       "       [  5.20151949,  -0.77531481,  -2.08489585, ...,  -5.72092247,\n",
       "          5.49588871,   4.27674007],\n",
       "       [  7.06528807,  -2.00259781,  -1.57315409, ...,  -6.34839916,\n",
       "          8.38027191,   5.27300692],\n",
       "       ..., \n",
       "       [  6.75482035,  -0.32357758,  -3.92642164, ..., -11.23333645,\n",
       "          7.89738274,   8.98905754],\n",
       "       [  5.86392879,  -0.26254541,  -0.15559515, ...,  -3.0988152 ,\n",
       "          7.37815475,   7.0153985 ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('breed_glove_matrix.npy', breed_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([114,  63,  82,  37,  79,  70,  84,  13,  56,  83,  97,  29,  46,\n",
       "       105,  64,  59,  30,  54,  32,  66,  57,  73,  14,  91,  67,  23,\n",
       "        98,  74,  60,  40,  62,  33,  27,  61,  94, 104,  90,  86,  58,\n",
       "        55,  15,  28,  16,  34,  24, 103,  95, 108,  76,  87,  75,  89,\n",
       "        81, 110,  52,  45,  11,  26,  17,  12,  47,  71,  25,   8,  80,\n",
       "        88,  96,  19,  92,  78, 102,  41, 111,  65,  31,  48,  68,  39,\n",
       "       112,  22,  38,  69,   5,  42,  18,  35,  21,  10,  44,   7,  51,\n",
       "        72, 107,   6, 100, 113,  49,   9,  20, 106,  93,  77,   3,  50,\n",
       "         4,  43,   0, 109, 101,   2,  36,  99,  85,  53,   1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(cosine_similarity((wiki_w2v['apartment']).reshape(1, -1), breed_mat)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.29916795,  0.32994977,  0.36641484,  0.36856291,\n",
       "        0.36914406,  0.37304946,  0.37386154,  0.37935054,  0.37950443,\n",
       "        0.3811247 ,  0.38220287,  0.38444102,  0.38475004,  0.38527763,\n",
       "        0.38735825,  0.38977064,  0.39056499,  0.39115811,  0.39195703,\n",
       "        0.3943784 ,  0.39608334,  0.39713538,  0.39808329,  0.3998926 ,\n",
       "        0.40137057,  0.40152298,  0.40282064,  0.40472544,  0.40571255,\n",
       "        0.40723348,  0.40762689,  0.40783887,  0.40903474,  0.41225996,\n",
       "        0.4131129 ,  0.41560581,  0.41707098,  0.41776998,  0.42061047,\n",
       "        0.42081472,  0.42117322,  0.4222803 ,  0.42446258,  0.42474214,\n",
       "        0.42621602,  0.42714755,  0.42735732,  0.42768688,  0.4371028 ,\n",
       "        0.43778829,  0.43786065,  0.43997885,  0.44172749,  0.44261593,\n",
       "        0.44282651,  0.44413139,  0.45022266,  0.45134529,  0.45254394,\n",
       "        0.4533395 ,  0.45509903,  0.45523257,  0.4562121 ,  0.45761025,\n",
       "        0.45991338,  0.46163454,  0.46303357,  0.46632928,  0.46730781,\n",
       "        0.46903634,  0.47096907,  0.47230288,  0.4742426 ,  0.47517164,\n",
       "        0.47733321,  0.47787636,  0.48009625,  0.48190299,  0.48452405,\n",
       "        0.48470784,  0.48558818,  0.48583542,  0.48707093,  0.49046187,\n",
       "        0.49303959,  0.49307257,  0.49497076,  0.49822026,  0.49967569,\n",
       "        0.50130685,  0.5025119 ,  0.50279257,  0.50633116,  0.50754979,\n",
       "        0.51056645,  0.51188917,  0.51580664,  0.51901972,  0.52239719,\n",
       "        0.52443989,  0.53105442,  0.53941893,  0.54976045,  0.56296889,\n",
       "        0.56606083,  0.56895863,  0.5700602 ,  0.57330873,  0.58008774,\n",
       "        0.5835648 ,  0.59310972,  0.59822547,  0.59916888,  0.65170152])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(cosine_similarity((wiki_w2v['apartment']).reshape(1, -1), breed_mat)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.4590567 ,  0.50628971,  0.56224334,  0.56553944,\n",
       "        0.56643118,  0.57242381,  0.57366989,  0.58209247,  0.5823286 ,\n",
       "        0.58481481,  0.5864692 ,  0.58990352,  0.59037769,  0.59118725,\n",
       "        0.59437985,  0.59808152,  0.59930042,  0.60021053,  0.60143643,\n",
       "        0.60515189,  0.60776802,  0.60938231,  0.61083683,  0.61361312,\n",
       "        0.61588098,  0.61611485,  0.61810604,  0.62102885,  0.62254351,\n",
       "        0.62487728,  0.62548095,  0.62580622,  0.62764123,  0.63259014,\n",
       "        0.63389894,  0.63772417,  0.63997239,  0.64104497,  0.64540355,\n",
       "        0.64571695,  0.64626705,  0.64796581,  0.65131439,  0.65174337,\n",
       "        0.65400495,  0.65543433,  0.65575621,  0.6562619 ,  0.67071011,\n",
       "        0.67176196,  0.67187299,  0.67512325,  0.67780645,  0.67916971,\n",
       "        0.67949284,  0.68149509,  0.69084181,  0.69256443,  0.69440369,\n",
       "        0.69562443,  0.69832433,  0.69852924,  0.70003228,  0.70217766,\n",
       "        0.70571169,  0.70835272,  0.71049945,  0.71555653,  0.71705804,\n",
       "        0.71971037,  0.72267603,  0.72472269,  0.72769908,  0.72912465,\n",
       "        0.73244146,  0.73327489,  0.73668119,  0.73945353,  0.74347541,\n",
       "        0.74375742,  0.74510825,  0.74548763,  0.74738346,  0.75258666,\n",
       "        0.75654203,  0.75659264,  0.7595053 ,  0.76449148,  0.76672476,\n",
       "        0.76922768,  0.77107676,  0.77150744,  0.77693721,  0.77880712,\n",
       "        0.78343603,  0.78546567,  0.79147681,  0.7964071 ,  0.80158965,\n",
       "        0.80472406,  0.81487368,  0.82770856,  0.84357705,  0.86384467,\n",
       "        0.86858909,  0.87303561,  0.8747259 ,  0.87971059,  0.89011261,\n",
       "        0.89544796,  0.91009412,  0.91794395,  0.91939156,  1.        ])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(cosine_similarity((wiki_w2v['apartment']).reshape(1, -1), breed_mat)[0] / \\\n",
    "        np.max(cosine_similarity((wiki_w2v['apartment']).reshape(1, -1), breed_mat)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n02085620-Chihuahua': 0,\n",
       " 'n02085782-Japanese_spaniel': 1,\n",
       " 'n02085936-Maltese_dog': 2,\n",
       " 'n02086079-Pekinese': 3,\n",
       " 'n02086240-Shih-Tzu': 4,\n",
       " 'n02086646-Blenheim_spaniel': 5,\n",
       " 'n02086910-papillon': 6,\n",
       " 'n02087046-toy_terrier': 7,\n",
       " 'n02087394-Rhodesian_ridgeback': 8,\n",
       " 'n02088094-Afghan_hound': 9,\n",
       " 'n02088238-basset': 10,\n",
       " 'n02088364-beagle': 11,\n",
       " 'n02088466-bloodhound': 12,\n",
       " 'n02088632-bluetick': 13,\n",
       " 'n02089078-black-and-tan_coonhound': 14,\n",
       " 'n02089867-Walker_hound': 15,\n",
       " 'n02089973-English_foxhound': 16,\n",
       " 'n02090379-redbone': 17,\n",
       " 'n02090622-borzoi': 18,\n",
       " 'n02090721-Irish_wolfhound': 19,\n",
       " 'n02091032-Italian_greyhound': 20,\n",
       " 'n02091134-whippet': 21,\n",
       " 'n02091244-Ibizan_hound': 22,\n",
       " 'n02091467-Norwegian_elkhound': 23,\n",
       " 'n02091635-otterhound': 24,\n",
       " 'n02091831-Saluki': 25,\n",
       " 'n02092002-Scottish_deerhound': 26,\n",
       " 'n02092339-Weimaraner': 27,\n",
       " 'n02093256-Staffordshire_bullterrier': 28,\n",
       " 'n02093428-American_Staffordshire_terrier': 29,\n",
       " 'n02093647-Bedlington_terrier': 30,\n",
       " 'n02093754-Border_terrier': 31,\n",
       " 'n02093859-Kerry_blue_terrier': 32,\n",
       " 'n02093991-Irish_terrier': 33,\n",
       " 'n02094114-Norfolk_terrier': 34,\n",
       " 'n02094258-Norwich_terrier': 35,\n",
       " 'n02094433-Yorkshire_terrier': 36,\n",
       " 'n02095314-wire-haired_fox_terrier': 37,\n",
       " 'n02095570-Lakeland_terrier': 38,\n",
       " 'n02095889-Sealyham_terrier': 39,\n",
       " 'n02096051-Airedale': 40,\n",
       " 'n02096177-cairn': 41,\n",
       " 'n02096294-Australian_terrier': 42,\n",
       " 'n02096437-Dandie_Dinmont': 43,\n",
       " 'n02096585-Boston_bull': 44,\n",
       " 'n02097047-miniature_schnauzer': 45,\n",
       " 'n02097130-giant_schnauzer': 46,\n",
       " 'n02097209-standard_schnauzer': 47,\n",
       " 'n02097298-Scotch_terrier': 48,\n",
       " 'n02097474-Tibetan_terrier': 49,\n",
       " 'n02097658-silky_terrier': 50,\n",
       " 'n02098105-soft-coated_wheaten_terrier': 51,\n",
       " 'n02098286-West_Highland_white_terrier': 52,\n",
       " 'n02098413-Lhasa': 53,\n",
       " 'n02099267-flat-coated_retriever': 54,\n",
       " 'n02099429-curly-coated_retriever': 55,\n",
       " 'n02099601-golden_retriever': 56,\n",
       " 'n02099712-Labrador_retriever': 57,\n",
       " 'n02099849-Chesapeake_Bay_retriever': 58,\n",
       " 'n02100236-German_short-haired_pointer': 59,\n",
       " 'n02100583-vizsla': 60,\n",
       " 'n02100735-English_setter': 61,\n",
       " 'n02100877-Irish_setter': 62,\n",
       " 'n02101006-Gordon_setter': 63,\n",
       " 'n02101388-Brittany_spaniel': 64,\n",
       " 'n02101556-clumber': 65,\n",
       " 'n02102040-English_springer': 66,\n",
       " 'n02102177-Welsh_springer_spaniel': 67,\n",
       " 'n02102318-cocker_spaniel': 68,\n",
       " 'n02102480-Sussex_spaniel': 69,\n",
       " 'n02102973-Irish_water_spaniel': 70,\n",
       " 'n02104029-kuvasz': 71,\n",
       " 'n02104365-schipperke': 72,\n",
       " 'n02105056-groenendael': 73,\n",
       " 'n02105162-malinois': 74,\n",
       " 'n02105251-briard': 75,\n",
       " 'n02105505-komondor': 76,\n",
       " 'n02105641-Old_English_sheepdog': 77,\n",
       " 'n02105855-Shetland_sheepdog': 78,\n",
       " 'n02106030-collie': 79,\n",
       " 'n02106166-Border_collie': 80,\n",
       " 'n02106382-Bouvier_des_Flandres': 81,\n",
       " 'n02106550-Rottweiler': 82,\n",
       " 'n02106662-German_shepherd': 83,\n",
       " 'n02107142-Doberman': 84,\n",
       " 'n02107312-miniature_pinscher': 85,\n",
       " 'n02107574-Greater_Swiss_Mountain_dog': 86,\n",
       " 'n02107683-Bernese_mountain_dog': 87,\n",
       " 'n02107908-Appenzeller': 88,\n",
       " 'n02108000-EntleBucher': 89,\n",
       " 'n02108089-boxer': 90,\n",
       " 'n02108422-bull_mastiff': 91,\n",
       " 'n02108551-Tibetan_mastiff': 92,\n",
       " 'n02108915-French_bulldog': 93,\n",
       " 'n02109047-Great_Dane': 94,\n",
       " 'n02109525-Saint_Bernard': 95,\n",
       " 'n02109961-Eskimo_dog': 96,\n",
       " 'n02110063-malamute': 97,\n",
       " 'n02110185-Siberian_husky': 98,\n",
       " 'n02110627-affenpinscher': 99,\n",
       " 'n02110806-basenji': 100,\n",
       " 'n02110958-pug': 101,\n",
       " 'n02111129-Leonberg': 102,\n",
       " 'n02111277-Newfoundland': 103,\n",
       " 'n02111500-Great_Pyrenees': 104,\n",
       " 'n02111889-Samoyed': 105,\n",
       " 'n02112018-Pomeranian': 106,\n",
       " 'n02112137-chow': 107,\n",
       " 'n02112350-keeshond': 108,\n",
       " 'n02112706-Brabancon_griffon': 109,\n",
       " 'n02113023-Pembroke': 110,\n",
       " 'n02113186-Cardigan': 111,\n",
       " 'n02113799-standard_poodle': 112,\n",
       " 'n02113978-Mexican_hairless': 113,\n",
       " 'not_dog': 114}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test potential user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = \"Hello: this is a sentence with punctuation! Doesn't it look great?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ':',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sentence',\n",
       " 'with',\n",
       " 'punctuation',\n",
       " '!',\n",
       " 'Does',\n",
       " \"n't\",\n",
       " 'it',\n",
       " 'look',\n",
       " 'great',\n",
       " '?']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sentence',\n",
       " 'with',\n",
       " 'punctuation',\n",
       " 'Doesn',\n",
       " 't',\n",
       " 'it',\n",
       " 'look',\n",
       " 'great']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.compile('\\w+').findall(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ':',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sentence',\n",
       " 'with',\n",
       " 'punctuation',\n",
       " '!',\n",
       " 'Doesn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'it',\n",
       " 'look',\n",
       " 'great',\n",
       " '?']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.regexp.WordPunctTokenizer().tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71795842658489328"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_w2v.similarity('big', 'small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.57309994e-01,   3.95300001e-01,   6.35860026e-01,\n",
       "        -1.09749997e+00,  -9.57679987e-01,  -1.38410004e-02,\n",
       "        -1.98530003e-01,   2.54180014e-01,   3.67309988e-01,\n",
       "        -1.74860001e-01,   2.76849985e-01,   3.19429994e-01,\n",
       "         3.00779998e-01,   6.85309991e-02,  -1.59170002e-01,\n",
       "        -2.19439998e-01,   6.40970021e-02,   8.47450018e-01,\n",
       "        -6.19889975e-01,   5.41729987e-01,   2.79210001e-01,\n",
       "         5.03830016e-01,   2.14600004e-02,  -2.05709994e-01,\n",
       "         7.79939964e-02,   3.22290003e-01,  -4.91829991e-01,\n",
       "        -1.14110005e+00,   2.33329996e-01,  -5.43579996e-01,\n",
       "         9.22849998e-02,   8.68600011e-01,   6.91270009e-02,\n",
       "         1.92289993e-01,   2.83740014e-01,   4.60139990e-01,\n",
       "        -2.83199996e-01,   4.53839988e-01,   3.52090001e-01,\n",
       "        -4.91730005e-01,  -1.47709996e-01,  -7.17670023e-02,\n",
       "        -2.43550003e-01,  -6.30890012e-01,  -6.77969992e-01,\n",
       "        -1.31640002e-01,   3.59739989e-01,  -7.52919972e-01,\n",
       "         3.82039994e-02,  -1.76950002e+00,   1.88930005e-01,\n",
       "        -1.88720003e-01,  -2.02680007e-01,   8.30900013e-01,\n",
       "         7.78699964e-02,  -2.62129998e+00,   8.19410011e-02,\n",
       "         2.72619992e-01,   1.62160003e+00,   8.61660004e-01,\n",
       "        -2.15820000e-01,   1.00979996e+00,  -7.81220019e-01,\n",
       "        -1.16630003e-01,   1.06289995e+00,   1.58299997e-01,\n",
       "         1.10090005e+00,   7.03239977e-01,  -6.04809999e-01,\n",
       "        -4.59069997e-01,   7.98619986e-02,  -6.17940009e-01,\n",
       "        -9.38960016e-02,  -5.03629982e-01,  -1.22170001e-01,\n",
       "        -1.78569998e-03,  -3.22350003e-02,  -1.05899997e-01,\n",
       "        -6.92319989e-01,   7.64850006e-02,   6.03839993e-01,\n",
       "        -5.60750008e-01,  -9.63720024e-01,  -7.01920018e-02,\n",
       "        -2.07879996e+00,  -5.64230025e-01,   1.75740004e-01,\n",
       "        -2.49610003e-02,  -4.53489989e-01,  -3.92870009e-01,\n",
       "        -8.05730000e-02,  -3.76340002e-01,   3.50829996e-02,\n",
       "        -3.96620005e-01,  -7.61650026e-01,   1.51130006e-01,\n",
       "        -1.30329996e-01,  -2.85129994e-01,   1.98530003e-01,\n",
       "         6.74640000e-01], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_w2v[\"n't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_input(sentence):\n",
    "    \"\"\"\n",
    "    Tokenizes a sentence, removes punctuation, and converts to lowercase letters.\n",
    "    \"\"\"\n",
    "    translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "    sentence_list = sentence.split()\n",
    "    return [x.translate(translate_table).lower() for x in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vec = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenize_input(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    word_vec += wiki_w2v[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114,  63,  82,  84,  59,  68,  56,  65,  29,  93,  90,  67,  40,\n",
       "         79,  80, 106,  57,  66,  17,  52,  13, 110, 109,  70,  37,  46,\n",
       "         83, 108,  60, 113,  55,  50,  10,  28,  54,  32,  30,  96,  27,\n",
       "         74,  64,  62,  45,   6,  23, 101,  76,   2,   5, 112, 105,  11,\n",
       "         97, 111,  16,  73,  42,  14,  34,  61,  58,  51,  98, 103,  44,\n",
       "          3,  99,  15,  94,   1,   0,  41,  22,   7,  21,  35,  33,  20,\n",
       "         81,  89,  85,  12,  78,  69,  88,  77,  31,  87,   8,  49,   4,\n",
       "         86,  75,  39,  43, 100,  48, 104,  18,  95,  25,  38,  47,  91,\n",
       "         24,  72,  53,  19,  26,  36,  92,   9, 107, 102,  71]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(cosine_similarity(word_vec.reshape(1, -1), breed_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = tokenize_input(\"A sentence that may contain a word you've not seen before: l'cie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_words(model, words):\n",
    "    \"\"\"\n",
    "    Take a list of words, and convert it into the sum of the word vectors\n",
    "    for the model, ignoring out of vocabulary words\n",
    "    \"\"\"\n",
    "    word_vec = np.zeros(len(model['you']))\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vec += wiki_w2v[word]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog_desc = \"playful, affectionate children\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog_vec = vectorize_words(wiki_w2v, tokenize_input(dog_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114, 107,   1,  76,  50,  71,  36,   3,  45,   2,  42,  32, 106,\n",
       "         58,  97,  75,  99,  47, 113,  46,  18,  68,   9,  38,  81,  15,\n",
       "        104, 102,  37,  25,   6,  53,  26,  85,  19,  52,  34,  40,  43,\n",
       "        111,  70,  74,  88,  65,  20,  16,  63,  48,   4,  23,  69, 110,\n",
       "        103,  87,  78,   7,  39,   8,  73, 112, 100,   0,  80,  24,  67,\n",
       "         86,  77,  66,  35,  14,  72, 101,  60,  31,  30,  21,  44,  33,\n",
       "         59, 105,  49,  84,  27,  79,  11,  51,  22,  92,  62,  61,  96,\n",
       "         41,  12,  94,  89,  95,  10,  93, 109,  54,  55,   5,  91,  64,\n",
       "         83,  98, 108,  90,  13,  82,  57,  28,  29,  56,  17]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(cosine_similarity(dog_vec.reshape(1, -1), breed_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use first 100,000 words in GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open(os.path.join('data', 'glove.6B.50d.txt'))\n",
    "i = 0\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    i += 1 \n",
    "    if i >= 100000:\n",
    "        break\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict()\n",
    "for idx, word in enumerate(embeddings_index.keys()):\n",
    "    word_index[word] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index)+1, 50))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index)+1,\n",
    "                            100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.14189994,  0.21620999,  0.05988   , -0.22087   ,  0.72100002,\n",
       "        0.55394   , -0.85043001, -0.27485001,  0.0788    , -0.54447001,\n",
       "       -0.16458   , -0.39355001,  0.94567001,  0.3132    , -0.57388002,\n",
       "        0.006172  ,  0.51563001,  0.59235001, -0.54390001, -1.10969996,\n",
       "        0.13733   , -0.66900998, -0.16584   ,  0.44869   , -0.42888999,\n",
       "       -1.12249994, -0.43607   ,  0.55676001,  0.39962   , -0.25964001,\n",
       "        3.85430002, -0.33091   ,  0.38144001,  0.059943  ,  0.19653   ,\n",
       "        0.50616997, -0.41123   ,  0.16168   ,  0.1503    , -0.061063  ,\n",
       "       -0.0063997 ,  0.1881    , -0.037663  ,  0.29605001,  0.46123999,\n",
       "        0.0066039 , -0.30737999, -0.64137   , -0.058311  , -0.45848   ], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove_vec_dict.p', 'wb') as file:\n",
    "    pickle.dump(embeddings_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14924"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['bark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3742"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['quiet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_word = {v: k for k, v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'persecution'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4758\n",
      "2431\n",
      "7935\n",
      "2431\n",
      "3841\n",
      "16531\n",
      "194\n",
      "8213\n",
      "1876\n",
      "29986\n",
      "4474\n",
      "38707\n",
      "357\n",
      "3742\n",
      "102547\n"
     ]
    }
   ],
   "source": [
    "for trait in trait_antonyms.values():\n",
    "    try:\n",
    "        print(word_index[trait[:-1]])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44400"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['obedient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
